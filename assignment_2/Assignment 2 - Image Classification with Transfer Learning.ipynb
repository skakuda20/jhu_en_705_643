{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1b7fba-4468-4fb6-982c-640136982165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f5641ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55ceec",
   "metadata": {},
   "source": [
    "### Part 1: Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da2c8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class IntelImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom class to wrap around Intel Image dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, split=\"seg_train\", transform=None):\n",
    "        \"\"\"\n",
    "        Init function for the class\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        # Define class labels\n",
    "        self.classes = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
    "        self.class_indices =  {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "        # Init images and labels\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.data_dir = os.path.join(root_dir, split)\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(self.data_dir, class_name)\n",
    "            \n",
    "            # Handle non existant paths\n",
    "            if not os.path.exists(class_dir):\n",
    "                continue\n",
    "            \n",
    "            # Parse paths\n",
    "            for image_path in os.listdir(class_dir):\n",
    "                # if image_path.endswith(\".jpg\", \".jpeg\", \"png\"):\n",
    "                \n",
    "                self.images.append(os.path.join(class_dir, image_path))\n",
    "                self.labels.append(self.class_indices[class_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Len member function\n",
    "        \"\"\"\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get member function\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Load image\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b39ed892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization (ImageNet)\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddbd2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Datasets\n",
    "train_data = IntelImageDataset(\"./data/seg_train/\", \"seg_train/\", transform)\n",
    "test_data = IntelImageDataset(\"./data/seg_test/\", \"seg_test/\", transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "add5fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "# Initialize Dataloaders\n",
    "# indices = list(range(len(train_data.labels)))\n",
    "# np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "\n",
    "dataset_size = len(train_data)\n",
    "train_size = int(0.85 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "# train_indices = indices[:split]\n",
    "# val_indices = indices[split:]\n",
    "\n",
    "train_data, val_data = random_split(train_data, [train_size, val_size])\n",
    "\n",
    "# train_sampler = SubsetRandomSampler(train_indices)\n",
    "# val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047fe784",
   "metadata": {},
   "source": [
    "### Part 2: Train Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d41b4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Model training loop\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch+1) % 100 == 0:\n",
    "            print(f\"Step [{batch+1}/{len(dataloader)}], Loss: {running_loss/100:.4f}\")\n",
    "            # print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch+1}/{len(dataloader)}], \"\n",
    "            #       f\"Loss: {running_loss / 100:.4f}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3405edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    \"\"\"\n",
    "    Model test loop\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    size = len(dataloader)\n",
    "    # test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            pred = outputs\n",
    "            _, pred = torch.max(outputs, dim=1) # TODO: check functionality\n",
    "            \n",
    "\n",
    "            # test_loss += loss_fn(pred, labels).item()\n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum().item()\n",
    "    \n",
    "    # test_loss /= size\n",
    "    correct /= total\n",
    "    print(f\"Test Error: \\n Accuracy: {100*correct:>1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830f6ba5",
   "metadata": {},
   "source": [
    "### Part 3: Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b58dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First try with ResNet-50\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "num_labels = 6  # TODO: make this dynamic\n",
    "model.fc = nn.Linear(num_ftrs, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bb8f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12006a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "# Check for CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa40892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/373], Loss: 1.7907\n",
      "Step [200/373], Loss: 1.6560\n",
      "Step [300/373], Loss: 1.5360\n",
      "Test Error: \n",
      " Accuracy: 65.800000%\n",
      "Epoch: [2/10]\n",
      "Step [100/373], Loss: 1.3472\n",
      "Step [200/373], Loss: 1.2633\n",
      "Step [300/373], Loss: 1.1733\n",
      "Test Error: \n",
      " Accuracy: 81.433333%\n",
      "Epoch: [3/10]\n",
      "Step [100/373], Loss: 1.0609\n",
      "Step [200/373], Loss: 0.9892\n",
      "Step [300/373], Loss: 0.9336\n",
      "Test Error: \n",
      " Accuracy: 86.066667%\n",
      "Epoch: [4/10]\n",
      "Step [100/373], Loss: 0.8447\n",
      "Step [200/373], Loss: 0.8105\n",
      "Step [300/373], Loss: 0.7685\n",
      "Test Error: \n",
      " Accuracy: 86.933333%\n",
      "Epoch: [5/10]\n",
      "Step [100/373], Loss: 0.7102\n",
      "Step [200/373], Loss: 0.6618\n",
      "Step [300/373], Loss: 0.6393\n",
      "Test Error: \n",
      " Accuracy: 88.400000%\n",
      "Epoch: [6/10]\n",
      "Step [100/373], Loss: 0.5907\n",
      "Step [200/373], Loss: 0.5727\n",
      "Step [300/373], Loss: 0.5544\n",
      "Test Error: \n",
      " Accuracy: 89.033333%\n",
      "Epoch: [7/10]\n",
      "Step [100/373], Loss: 0.5129\n",
      "Step [200/373], Loss: 0.4978\n",
      "Step [300/373], Loss: 0.4775\n",
      "Test Error: \n",
      " Accuracy: 89.466667%\n",
      "Epoch: [8/10]\n",
      "Step [100/373], Loss: 0.4565\n",
      "Step [200/373], Loss: 0.4477\n",
      "Step [300/373], Loss: 0.4212\n",
      "Test Error: \n",
      " Accuracy: 90.333333%\n",
      "Epoch: [9/10]\n",
      "Step [100/373], Loss: 0.4000\n",
      "Step [200/373], Loss: 0.4165\n",
      "Step [300/373], Loss: 0.3889\n",
      "Test Error: \n",
      " Accuracy: 90.733333%\n",
      "Epoch: [10/10]\n",
      "Step [100/373], Loss: 0.3853\n",
      "Step [200/373], Loss: 0.3770\n",
      "Step [300/373], Loss: 0.3655\n",
      "Test Error: \n",
      " Accuracy: 90.733333%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: [{epoch+1}/{num_epochs}]\")\n",
    "    train_loop(train_dataloader, model, criterion, optimizer, device)\n",
    "    test_loop(test_dataloader, model, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3605047c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 91.737892%\n"
     ]
    }
   ],
   "source": [
    "# Validation Accuracy\n",
    "test_loop(val_dataloader, model, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5893b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
