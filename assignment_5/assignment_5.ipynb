{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1209bb3d",
   "metadata": {},
   "source": [
    "# Assignment 5 Vision Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d72079",
   "metadata": {},
   "source": [
    "## Part 1 - Load CIFAR100 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e129a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69daa93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169M/169M [00:04<00:00, 36.6MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR100\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download CIFAR10 data\n",
    "torchvision.datasets.CIFAR100(root=\"./data\", train=True, download=True)\n",
    "torchvision.datasets.CIFAR100(root=\"./data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1774444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class CustomImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom class to wrap around CIFAR100 dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, train=True, transform=None, target_transform=None):\n",
    "        \"\"\"\n",
    "        Init function for the class\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        batch_files = [\"train\"] if train else [\"test\"]\n",
    "        self.data, self.labels = [], []\n",
    "\n",
    "         # Load the batch file(s)\n",
    "        for batch in batch_files:\n",
    "            with open(os.path.join(data_path, \"cifar-100-python\", f\"{batch}\"), \"rb\") as f:\n",
    "                batch_dict = pickle.load(f, encoding=\"bytes\")\n",
    "                self.data.append(batch_dict[b\"data\"])  # Image data (flattened)\n",
    "                self.labels.extend(batch_dict[b\"fine_labels\"])  # Fine-grained labels (100 classes)\n",
    "\n",
    "        # Reshape data to (N, 3, 32, 32)\n",
    "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Len member function\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get member function\n",
    "        \"\"\"\n",
    "        image = self.data[idx].transpose((1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split dataset into train, test, and validate\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899dba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Datasets\n",
    "train_data = CustomImageDataset(\"./data/\", train=True)\n",
    "test_data = CustomImageDataset(\"./data/\", train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c7b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Dataloaders\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db65824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
