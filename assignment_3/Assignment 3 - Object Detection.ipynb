{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04359a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8283ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50c985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to ./data/VOCtrainval_11-May-2012.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 1999639040/1999639040 [01:32<00:00, 21608176.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"./data\"\n",
    "voc_dataset = torchvision.datasets.VOCDetection(\n",
    "    root=root_dir,  # Directory where the dataset will be downloaded\n",
    "    year=\"2012\",  # Choose \"2007\" or \"2012\"\n",
    "    image_set=\"train\",  # Options: \"train\", \"val\", \"trainval\", \"test\" (2007 has \"test\")\n",
    "    download=True,  # Download dataset if not available\n",
    "    transform=transforms.ToTensor()  # Convert images to tensor\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d503e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check that the first 10 xml anotations match the first 10 JPEG images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f866b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader\n",
    "dataloader = DataLoader(voc_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2d552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
